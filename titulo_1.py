# -*- coding: utf-8 -*-
"""titulo 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nRuuYRqU_w8p8E_YkW4A1214ZfrzpuMv

Instalacion de dependencias necesarias
"""

!pip install transformers

"""Importacion de bibliotecas"""

from transformers import BertTokenizer, BertModel
import torch

"""importacion de Bert y TOkenizador"""

# Import necessary libraries
from transformers import BertTokenizer, BertModel
import torch

# Now you can use BertTokenizer and BertModel
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained('bert-base-uncased')

"""entrenamiento


"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error

"""Cargar los datos"""

file_path = "Entrenamientooo.csv"  # Reemplaza con el nombre correcto del archivo
data = pd.read_csv(file_path)

""" Verificar los datos"""

print(data.head())

"""Estructurar Datos"""

data.columns = data.columns.str.strip()  # Elimina espacios
data.columns = data.columns.str.replace(" ", "_")  # Reemplaza espacios por guiones bajos
data.columns = data.columns.str.lower()  # Convierte a minúsculas
print(data.columns)

print(data.columns)

data = pd.read_csv("Entrenamientooo.csv", delimiter=";")
print(data.head())

print(data.columns)

"""Separar las columnas relevantes"""

X = data['descripcion del dano']
y = data['Monto Valorizado']

"""dvidir el subconjutno de datos

"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Vectorizar las descripciones de daños"""

vectorizer = TfidfVectorizer(max_features=1000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

"""# Entrenar modelo de regresión"""

new_var = 100
model = RandomForestRegressor(n_estimators=new_var, random_state=42)
model.fit(X_train_tfidf, y_train)

"""Precision estimada"""



y_pred = model.predict(X_test_tfidf)
mae = mean_absolute_error(y_test, y_pred)
print(f"Error Absoluto Medio (MAE): {mae}")

"""instalar pdf pumbler

"""

!pip install pdfplumber

"""Prueba 1"""

import pdfplumber
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestRegressor

# Función para extraer daños del PDF
def extract_damages_from_pdf(pdf_path):
    damages = ""
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            # Filtrar daños basados en palabras clave
            for line in text.split("\n"):
                if any(keyword in line.lower() for keyword in ["daño", "rotura", "fuga", "filtración", "humedad"]):
                    damages += line + " "
    return damages.strip()

# Pedir al usuario que ingrese la ruta al archivo PDF
while True:
    print("\nIntroduce la ruta completa del archivo PDF con el acta (o escribe 'salir' para terminar):")
    pdf_path = input("> ").strip()

    if pdf_path.lower() == 'salir':
        print("Finalizando el programa.")
        break

    try:
        # Extraer texto relevante del PDF
        damages_text = extract_damages_from_pdf(pdf_path)

        if not damages_text:
            print("No se encontraron daños en el acta. Intenta con otro archivo.")
            continue

        # Mostrar solo los daños extraídos
        print("\nDaños extraídos del PDF:")
        print(damages_text)

        # Convertir el texto de los daños a representación TF-IDF
        acta_tfidf = vectorizer.transform([damages_text])  # Asegúrate de que el vectorizador esté entrenado

        # Predecir el monto asociado con los daños extraídos
        predicted_value = model.predict(acta_tfidf)  # Asegúrate de que el modelo esté entrenado

        # Mostrar el resultado
        print(f"Predicción para el acta: {predicted_value[0]:.2f}")

    except FileNotFoundError:
        print("Error: No se encontró el archivo. Por favor verifica la ruta e inténtalo de nuevo.")
    except Exception as e:
        print(f"Error al procesar el archivo: {e}")

"""prueba 2"""

import pdfplumber
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestRegressor

# Función para extraer daños del PDF
def extract_damages_from_pdf(pdf_path):
    damages = ""
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            # Filtrar daños basados en palabras clave
            for line in text.split("\n"):
                if any(keyword in line.lower() for keyword in ["daño", "rotura", "fuga", "filtración", "humedad"]):
                    damages += line + " "
    return damages.strip()

# Ruta al archivo PDF
pdf_path = "3909.pdf"  # Reemplaza con la ruta al archivo PDF
damages_text = extract_damages_from_pdf(pdf_path)

# Mostrar solo los daños extraídos
print("Daños extraídos del PDF:")
print(damages_text)

# Convertir el texto de los daños a representación TF-IDF
acta_tfidf = vectorizer.transform([damages_text])

# Predecir el monto asociado con los daños extraídos
predicted_value = model.predict(acta_tfidf)

# Mostrar el resultado
print(f"Predicción para el acta: {predicted_value[0]}")

"""prueba 3

"""

import pdfplumber
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestRegressor

# Función para extraer texto del PDF
def extract_text_from_pdf(pdf_path):
    text = ""
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text += page.extract_text()
    return text

# Ruta al archivo PDF
pdf_path = "3858.pdf"  # Reemplaza con el nombre del archivo PDF
acta_text = extract_text_from_pdf(pdf_path)

# Verificar el texto extraído
print("Texto extraído del PDF:")
print(acta_text)

# Convertir el texto a representación TF-IDF
acta_tfidf = vectorizer.transform([acta_text])

# Predecir el monto asociado con el texto del acta
predicted_value = model.predict(acta_tfidf)

# Mostrar el resultado
print(f"Predicción para el acta: {predicted_value[0]}")

import pdfplumber
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestRegressor

# Función para extraer daños del PDF
def extract_damages_from_pdf(pdf_path):
    damages = ""
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            # Filtrar daños basados en palabras clave
            for line in text.split("\n"):
                if any(keyword in line.lower() for keyword in ["daño", "rotura", "fuga", "filtración", "humedad"]):
                    damages += line + " "
    return damages.strip()

# Ruta al archivo PDF
pdf_path = "3858.pdf"  # Reemplaza con la ruta al archivo PDF
damages_text = extract_damages_from_pdf(pdf_path)

# Mostrar solo los daños extraídos
print("Daños extraídos del PDF:")
print(damages_text)

# Convertir el texto de los daños a representación TF-IDF
acta_tfidf = vectorizer.transform([damages_text])

# Predecir el monto asociado con los daños extraídos
predicted_value = model.predict(acta_tfidf)

# Mostrar el resultado
print(f"Predicción para el acta: {predicted_value[0]}")

"""GUARDAR MODELO

"""

import joblib

# Guardar el modelo entrenado
joblib.dump(model, 'model.pkl')

# Guardar el vectorizador entrenado
joblib.dump(vectorizer, 'vectorizer.pkl')

from google.colab import files

files.download('model.pkl')
files.download('vectorizer.pkl')